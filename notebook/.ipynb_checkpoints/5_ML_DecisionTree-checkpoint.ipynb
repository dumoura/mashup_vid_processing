{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings - Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings - Directories and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dumoura/Dev/PDev/Mashup_Vid_Processing/notebook\n"
     ]
    }
   ],
   "source": [
    "#os.chdir(\".../notebook\")\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diret칩rios e locais de trabalho\n",
    "\n",
    "#Base_dir\n",
    "BASE_DIR = os.path.dirname(cwd) # base de trabalho\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\") # dados gerais levantados durante projeto\n",
    "META_DIR = os.path.join(BASE_DIR, \"metadados\") #metadados levantados durante projeto\n",
    "SAMPLE_DIR = os.path.join(DATA_DIR, \"sample\") # material em processo - pode ser apagado ao final, caso julgue necess치rio\n",
    "INPUTS_DIR = os.path.join(SAMPLE_DIR, \"inputs\") # local de trabalho para processamento de dados de midia \n",
    "OUTPUTS_DIR = os.path.join(SAMPLE_DIR, \"outputs\") # local de trabalho para processamento de dados de midia \n",
    "\n",
    "#MASHUPS\n",
    "VIDS_DIR = os.path.join(DATA_DIR, \"vids\") # dados gerais levantados durante projeto\n",
    "\n",
    "#Inputs\n",
    "VID_DIR = os.path.join(INPUTS_DIR, \"vid_input\") # local de trabalho para processamento de dados de midia \n",
    "AUDIO_DIR = os.path.join(INPUTS_DIR, \"audio_input\") # local de trabalho para processamento de dados de midia # # Criar diret칩rios e locais de trabalho\n",
    "LGG_DIR = os.path.join(INPUTS_DIR, \"lgg_input\") # local de trabalho para processamento de dados de midia \n",
    "\n",
    "#Outputs\n",
    "FRAME_DIR = os.path.join(OUTPUTS_DIR, \"thumbnails\") # local de trabalho para processamento de dados de midia \n",
    "SONG_DIR = os.path.join(OUTPUTS_DIR, \"songs\") # local de trabalho para processamento de dados de midia # # Criar diret칩rios e locais de trabalho\n",
    "LYRIC_DIR = os.path.join(OUTPUTS_DIR, \"lyrics\") # local de trabalho para processamento de dados de midia \n",
    "\n",
    "#Make_dirs\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(META_DIR, exist_ok=True)\n",
    "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
    "os.makedirs(INPUTS_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
    "\n",
    "#Make_vids\n",
    "os.makedirs(VIDS_DIR, exist_ok=True)\n",
    "\n",
    "##Make_dirs inputs\n",
    "os.makedirs(VID_DIR , exist_ok=True)\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "os.makedirs(LGG_DIR, exist_ok=True)\n",
    "\n",
    "##Make_dirs outputs\n",
    "os.makedirs(FRAME_DIR, exist_ok=True)\n",
    "os.makedirs(SONG_DIR, exist_ok=True)\n",
    "os.makedirs(LYRIC_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading document to train and set the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.Rhistory',\n",
       " '.DS_Store',\n",
       " 'MlKeywordsClassified.csv',\n",
       " 'Vid24_WhiteStripesNirvana_ManualTagged.csv',\n",
       " 'Vid24_WhiteStripesNirvana_ML_Pred.csv']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(META_DIR)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_names to be use as dependent variable \n",
    "\n",
    "# col_names = ['file', 'imageID', 'Keywords', 'brightness_median', 'brightness_stdev','saturation_median', \n",
    "#              'saturation_stdev', 'hue_median', 'hue_stdev',\n",
    "#              'Count', 'Total Area', 'Average Size', '%Area']\n",
    "\n",
    "col_names = ['imageID', 'Keywords', 'brightness_median', 'brightness_stdev',\n",
    "       'saturation_median', 'saturation_stdev', 'hue_median', 'hue_stdev',\n",
    "       'Count', 'Total Area', 'Average Size', '%Area']\n",
    "\n",
    "df = pd.read_csv('Vid24_WhiteStripesNirvana_ManualTagged.csv', header=0, names=col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imageID', 'Keywords', 'brightness_median', 'brightness_stdev',\n",
       "       'saturation_median', 'saturation_stdev', 'hue_median', 'hue_stdev',\n",
       "       'Count', 'Total Area', 'Average Size', '%Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide given columns into two variables: dependent (or target variable) and independent (or feature variables)\n",
    "feature_cols = ['imageID', 'brightness_median', 'brightness_stdev',\n",
    "       'saturation_median', 'saturation_stdev', 'hue_median', 'hue_stdev',\n",
    "       'Count', 'Total Area', 'Average Size', '%Area',]\n",
    "\n",
    "X = df[feature_cols] #  dependent: feature variables\n",
    "y = df.Keywords # independent: target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset: training set and test set => 70% training and 30% test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion = 'gini') # the the regular criterion is 'gini', it was changed to 'entropy'. Also, the max_depth may be set as well.\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating  - How often is the classifier correct? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.Rhistory',\n",
       " '.DS_Store',\n",
       " 'MlKeywordsClassified.csv',\n",
       " 'Vid24_WhiteStripesNirvana_ManualTagged.csv',\n",
       " 'Vid24_WhiteStripesNirvana_ML_Pred.csv']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [ 'file', 'imageID', 'brightness_median', 'brightness_stdev',\n",
    "       'saturation_median', 'saturation_stdev', 'hue_median', 'hue_stdev',\n",
    "       'Count', 'Total Area', 'Average Size', '%Area']\n",
    "\n",
    "k_pred = pd.read_csv('Vid24_WhiteStripesNirvana_ML_Pred.csv', header=0, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_pred.columns\n",
    "k_pred = k_pred.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>saturation_median</th>\n",
       "      <th>saturation_stdev</th>\n",
       "      <th>hue_median</th>\n",
       "      <th>hue_stdev</th>\n",
       "      <th>Count</th>\n",
       "      <th>Total Area</th>\n",
       "      <th>Average Size</th>\n",
       "      <th>%Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>49.0545</td>\n",
       "      <td>106</td>\n",
       "      <td>29.5308</td>\n",
       "      <td>9</td>\n",
       "      <td>163049</td>\n",
       "      <td>18116.556</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.3077</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.3077</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18.3077</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>50.7772</td>\n",
       "      <td>106</td>\n",
       "      <td>22.2292</td>\n",
       "      <td>4</td>\n",
       "      <td>690</td>\n",
       "      <td>172.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imageID  saturation_median  saturation_stdev  hue_median  hue_stdev  Count  \\\n",
       "0        1                 85           49.0545         106    29.5308      9   \n",
       "1        2                  0           18.3077           0    13.7129      0   \n",
       "2        3                  0           18.3077           0    13.7129      0   \n",
       "3        4                  0           18.3077           0    13.7129      0   \n",
       "4        5                255           50.7772         106    22.2292      4   \n",
       "\n",
       "   Total Area  Average Size  %Area  \n",
       "0      163049     18116.556     88  \n",
       "1           0         0.000      0  \n",
       "2           0         0.000      0  \n",
       "3           0         0.000      0  \n",
       "4         690       172.500      0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_pred = k_pred.drop(columns=['file'])\n",
    "k_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(k_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "\n",
    "for i, row in enumerate(y_pred):\n",
    "    k.append((row))\n",
    "    \n",
    "k = pd.DataFrame(k, columns=[\"Keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Keywords\n",
      "0       B_Instrumental_main-track\n",
      "1     G_Lyrics_complementarytrack\n",
      "2     G_Lyrics_complementarytrack\n",
      "3     G_Lyrics_complementarytrack\n",
      "4       B_Instrumental_main-track\n",
      "...                           ...\n",
      "2625  G_Lyrics_complementarytrack\n",
      "2626  G_Lyrics_complementarytrack\n",
      "2627  G_Lyrics_complementarytrack\n",
      "2628  G_Lyrics_complementarytrack\n",
      "2629  G_Lyrics_complementarytrack\n",
      "\n",
      "[2630 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.to_csv(\"MlKeywordsClassified2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
